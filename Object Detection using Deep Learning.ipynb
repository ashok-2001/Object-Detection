{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8148514,"sourceType":"datasetVersion","datasetId":4818941},{"sourceId":8157011,"sourceType":"datasetVersion","datasetId":4825365}],"dockerImageVersionId":30684,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport xml.etree.ElementTree as ET\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-18T14:50:40.568122Z","iopub.execute_input":"2024-04-18T14:50:40.569372Z","iopub.status.idle":"2024-04-18T14:50:40.856568Z","shell.execute_reply.started":"2024-04-18T14:50:40.569329Z","shell.execute_reply":"2024-04-18T14:50:40.855441Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def parse_annotation(xml_file):\n    tree = ET.parse(xml_file)\n    root = tree.getroot()\n    boxes = []\n    labels = []\n    for obj in root.findall('object'):\n        label = obj.find('name').text\n        xmin = int(float(obj.find('bndbox/xmin').text))\n        ymin = int(float(obj.find('bndbox/ymin').text))\n        xmax = int(float(obj.find('bndbox/xmax').text))\n        ymax = int(float(obj.find('bndbox/ymax').text))\n        boxes.append([xmin, ymin, xmax, ymax])\n        labels.append(label)\n    return boxes, labels\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:50:40.858812Z","iopub.execute_input":"2024-04-18T14:50:40.859187Z","iopub.status.idle":"2024-04-18T14:50:40.868138Z","shell.execute_reply.started":"2024-04-18T14:50:40.859139Z","shell.execute_reply":"2024-04-18T14:50:40.867133Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def preprocess_voc2012_dataset(dataset_path, output_path, target_size=(224, 224)):\n    image_dir = os.path.join(dataset_path, 'JPEGImages')\n    annotation_dir = os.path.join(dataset_path, 'Annotations')\n    segmentation_object_dir = os.path.join(dataset_path, 'SegmentationObject')\n    segmentation_class_dir = os.path.join(dataset_path, 'SegmentationClass')\n\n    # Create output directory if it doesn't exist\n    if not os.path.exists(output_path):\n        os.makedirs(output_path)\n\n    # Loop through all images in the VOC2012 dataset\n    for filename in os.listdir(image_dir):\n        if filename.endswith('.jpg'):\n            # Read image\n            image_path = os.path.join(image_dir, filename)\n            image = cv2.imread(image_path)\n\n            # Read corresponding annotation file\n            annotation_path = os.path.join(annotation_dir, filename[:-4] + '.xml')\n            boxes, labels = parse_annotation(annotation_path)\n\n            # Resize image to target size\n            image = cv2.resize(image, target_size)\n\n            # Optionally normalize pixel values\n            # image = image.astype(np.float32) / 255.0\n\n            # Save preprocessed image\n            output_image_path = os.path.join(output_path, filename)\n            cv2.imwrite(output_image_path, image)\n\n            # Process segmentation mask (optional)\n            segmentation_object_path = os.path.join(segmentation_object_dir, filename[:-4] + '.png')\n            segmentation_class_path = os.path.join(segmentation_class_dir, filename[:-4] + '.png')\n            if os.path.exists(segmentation_object_path):\n                segmentation_object = cv2.imread(segmentation_object_path, cv2.IMREAD_GRAYSCALE)\n                segmentation_object = cv2.resize(segmentation_object, target_size)\n                cv2.imwrite(os.path.join(output_path, f\"{filename[:-4]}_segmentation_object.png\"), segmentation_object)\n            if os.path.exists(segmentation_class_path):\n                segmentation_class = cv2.imread(segmentation_class_path, cv2.IMREAD_GRAYSCALE)\n                segmentation_class = cv2.resize(segmentation_class, target_size)\n                cv2.imwrite(os.path.join(output_path, f\"{filename[:-4]}_segmentation_class.png\"), segmentation_class)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:50:40.869467Z","iopub.execute_input":"2024-04-18T14:50:40.870586Z","iopub.status.idle":"2024-04-18T14:50:40.885491Z","shell.execute_reply.started":"2024-04-18T14:50:40.870539Z","shell.execute_reply":"2024-04-18T14:50:40.884288Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Example usage:\ndataset_path = '/kaggle/input/voc2012/VOCdevkit/VOC2012'\noutput_path = '/kaggle/working/Preprocessed'\n\n# Preprocess the VOC2012 dataset\npreprocess_voc2012_dataset(dataset_path, output_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:50:40.888965Z","iopub.execute_input":"2024-04-18T14:50:40.889518Z","iopub.status.idle":"2024-04-18T14:56:07.394540Z","shell.execute_reply.started":"2024-04-18T14:50:40.889471Z","shell.execute_reply":"2024-04-18T14:56:07.393072Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:07.397556Z","iopub.execute_input":"2024-04-18T14:56:07.397943Z","iopub.status.idle":"2024-04-18T14:56:21.825693Z","shell.execute_reply.started":"2024-04-18T14:56:07.397910Z","shell.execute_reply":"2024-04-18T14:56:21.824246Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"2024-04-18 14:56:10.273978: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-18 14:56:10.274145: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-18 14:56:10.478689: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to load and preprocess images\ndef load_and_preprocess_image(image_path, target_size=(224, 224)):\n    img = load_img(image_path, target_size=target_size)\n    img_array = img_to_array(img)\n    img_array = preprocess_input(img_array)\n    return img_array","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:21.827218Z","iopub.execute_input":"2024-04-18T14:56:21.827918Z","iopub.status.idle":"2024-04-18T14:56:21.835286Z","shell.execute_reply.started":"2024-04-18T14:56:21.827880Z","shell.execute_reply":"2024-04-18T14:56:21.833869Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Function to load dataset and annotations\ndef load_dataset(dataset_path):\n    images = []\n    annotations = []\n    for filename in os.listdir(dataset_path):\n        if filename.endswith('.jpg'):\n            image_path = os.path.join(dataset_path, filename)\n            annotation_path = os.path.join(dataset_path, f\"{filename[:-4]}_annotation.txt\")  # Assuming annotations are stored in a separate text file\n            images.append(load_and_preprocess_image(image_path))\n            annotations.append(annotation_path)\n    return np.array(images), annotations","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:21.837294Z","iopub.execute_input":"2024-04-18T14:56:21.838038Z","iopub.status.idle":"2024-04-18T14:56:21.864884Z","shell.execute_reply.started":"2024-04-18T14:56:21.837994Z","shell.execute_reply":"2024-04-18T14:56:21.863790Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def build_faster_rcnn_model(num_classes, weights_path='/kaggle/input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'):\n    base_model = ResNet50(include_top=False, input_shape=(None, None, 3), weights=None)\n    base_model.load_weights(weights_path, by_name=True)\n    backbone = models.Model(inputs=base_model.input, outputs=base_model.layers[-4].output)\n\n    input_feature_map = layers.Input(shape=(None, None, 2048))\n    rpn = layers.Conv2D(512, (3, 3), padding='same', activation='relu')(input_feature_map)\n    rpn_cls_output = layers.Conv2D(num_anchors * 2, (1, 1), activation='softmax', name='rpn_cls_output')(rpn)\n    rpn_reg_output = layers.Conv2D(num_anchors * 4, (1, 1), activation='linear', name='rpn_reg_output')(rpn)\n\n    rpn_model = models.Model(inputs=input_feature_map, outputs=[rpn_cls_output, rpn_reg_output])\n\n    roi_input = layers.Input(shape=(None, 4))\n    pooled_regions = layers.RoiPoolingConv(7, 7)([input_feature_map, roi_input])\n    x = layers.TimeDistributed(layers.Flatten())(pooled_regions)\n    x = layers.TimeDistributed(layers.Dense(1024, activation='relu'))(x)\n    x = layers.TimeDistributed(layers.Dense(1024, activation='relu'))(x)\n\n    cls_output = layers.TimeDistributed(layers.Dense(num_classes, activation='softmax', kernel_initializer='zero'))(x)\n    reg_output = layers.TimeDistributed(layers.Dense(num_classes * 4, activation='linear', kernel_initializer='zero'))(x)\n\n    model = models.Model(inputs=[input_feature_map, roi_input], outputs=[cls_output, reg_output])\n    return backbone, rpn_model, model\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:21.866272Z","iopub.execute_input":"2024-04-18T14:56:21.866643Z","iopub.status.idle":"2024-04-18T14:56:21.880919Z","shell.execute_reply.started":"2024-04-18T14:56:21.866611Z","shell.execute_reply":"2024-04-18T14:56:21.879641Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ndataset_path = '/kaggle/working/Preprocessed'\nimages, annotations = load_dataset(dataset_path)\n\n# Define number of classes\nnum_classes = 20  # Assuming VOC dataset has 20 classes\n\n# Encode class labels\nlabel_encoder = LabelEncoder()\nlabels = [os.path.basename(annotation_path).split('_')[0] for annotation_path in annotations]\nlabels_encoded = label_encoder.fit_transform(labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:21.882655Z","iopub.execute_input":"2024-04-18T14:56:21.883190Z","iopub.status.idle":"2024-04-18T14:57:05.723717Z","shell.execute_reply.started":"2024-04-18T14:56:21.883120Z","shell.execute_reply":"2024-04-18T14:57:05.722505Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Split dataset into training and validation sets\ntrain_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size=0.2, random_state=42)\n\n# Define the number of anchors\nnum_anchors = 9  # You can adjust this value based on your requirements\n# Build Faster R-CNN model\n\nbackbone, rpn_model, model = build_faster_rcnn_model(num_classes)\n\n# Compile the model\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\nmodel.compile(optimizer=optimizer, loss=['categorical_crossentropy', 'mse'])\n\n# Train the model\nmodel.fit([train_images, train_annotations], [train_labels, train_bboxes], validation_data=([val_images, val_annotations], [val_labels, val_bboxes]), batch_size=16, epochs=10)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:58:36.584630Z","iopub.execute_input":"2024-04-18T14:58:36.585100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}